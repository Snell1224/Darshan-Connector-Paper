\section{Experimental Methodology}\label{AA}
In this section we will evaluate our framework using three applications: HACC-IO and MPI-IO benchmarks, and sw4 scientific application using a Cray HPC cluster.

\begin{table}[]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		File System	& Particles/Rank	& Runtime &	Nodes \\ \hline
		\multirow{2}{*}{NFS}	& 1000000	& 1210.06 &	16\\ \cline{2-4} 
		& 2000000	& 2455.60 &	16\\ \hline
		\multirow{2}{*}{Luster}	& 1000000	&  1476.643 &16 \\ \cline{2-4} 
		& 2000000	&  ?? &	16 \\ \hline
	\end{tabular}
	\caption{HACC-IO run configurations, targeted file system, and runtime}
	\label{table:HACC}
\end{table}


\subsection{Applications}
\begin{itemize}
	\item HACC-IO is the I/O proxy for the large scientific Hardware Accelerated Cosmology Code (HACC), an N-body framework that simulates the evolution of mass in the universe with short and long-range interactions~\cite{habib2013hacc}. The long-range solvers implement an underlying 3D FFT. HACC-IO is an MPI code that simulates the POSIX, MPI collective, and MPI independent I/O patterns of HACC and takes a number of particles per rank as input and filename to write out the simulation data. We ran HACC-IO with several configurations to simulate different workloads on the NFS and Luster file systems. Table~\ref{table:HACC} shows the different run configurations. 
	\item HMMER is a suite of applications that profiles are hidden Markov model (HMM) to search similar protein sequences~\cite{eddy1992hmmer}. HMMER has a building code that uses MPI to build a database by concatenating multiple profiles Stockholm alignment files. In our experiment, we used the Pfam-A.seed~\cite{sonnhammer1998pfam} file to generate a large Pfam-A.hmm. We ran HMMER with 32 MPI ranks on one node, and we ran it in two configurations where we point the database file to NFS and then Luster, respectively. 
	\item Dashan MPI-IO-TEST benchmark is a darshan utility that exists in the code distribution to test the MPI I/O performance on HPC machines. It can produce iterations of messages with different sizes sent from various MPI ranks. It can also simulate collective and independent MPI I/O methods. We ran several configurations of the benchmark where we \todo{...}
	\item sw4 is a geodynamics code that solves 3D seismic wave equations with local meshrefinement~\cite{peterssonsw4}. sw4 accepts an input file that specifies the 3D grid simulation size, and we selected a size that uses about 50\% of the available memory to memic a realistic run of the application.
\end{itemize}
%provides various use cases of the \Darshan timeseries data that will be used to create new meaningful analyses and insights in the I/O performance variability during an application run.

\subsection{Evaluation System}
We experiment using several I/O loads on the Voltrino Cray XC40 system at Sandia National Laboratories. The system has 24  diskless nodes with Dual Intel Xeon Haswell E5-2698 v3 @ 2.30GHz 16 cores, 32 threads/socket, 64 GB DDR3-1866MHz memory, and connected with a Cray Aries DragonFly interconnect. The machine has two file systems: the network file system (NFS) and the Luster file system (LFS).\todo{File systems???}

\subsection{Enviroment}
Voltrino, run LDMS samplers on the compute nodes and one LDMS aggregator on the head node. LDMS uses the UGNI interface to transfer darshan streams data and other performance metrics from the compute nodes to the head node. The aggregator on the head node transmits the data to another LDMS aggregator on another cluster, Shirley, for analysis and storage. Shirley, host the HPC web services Grafana application and the DSOS database. Darshan can wrap the I/O function in an application by linking the executables staticky and dynamic. Our framework uses dynamic linking to collect darshan data. So we set the \code{LD\_Preload} environment variable to point the path of the darshan library shared objects which have the LDMS streams API calls to send the data through the LDMS daemons live on the compute nodes. 

%\RED{Explain the different scenarios we will be testing:
%	\begin{itemize}
%		\item Applications: SWFFT, sw4, sw4lite. Standard baseline: mpi-test. 
%		\item Explain what each application does, why it's being tested and how the test was performed (i.e. number of nodes, etc.)
%		\item Explain the analysis used to analyze the I/O data and how they provide further insight into the I/O behavior and can allow for correlations between I/O performance and system behavior.
%		\item show Grafana graphs, Darshan output (maybe) JSON and any tables (if applicable).
%\end{itemize}}


\section{Results}
This section covers what significance of the approach to collecting runtime application I/O data and how the new analyses helped provide more insight into I/O behavior. 
%\RED{
%	\begin{itemize}
%		\item Analyse the results of the use cases
%		\item What is the significance of the results?
%		\item Throw in a picture of the Grafana Dashboard for each use case
%		\item How do these results satisfy and solve the problems described in the the "Problems and Approach" section.
%	\end{itemize}
%}  